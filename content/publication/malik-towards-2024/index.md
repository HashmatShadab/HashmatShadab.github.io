---
title: Towards Evaluating the Robustness of Visual State Space Models
authors:
- Hashmat Shadab Malik
- Fahad Shamshad
- Muzammal Naseer
- Karthik Nandakumar
- Fahad Shahbaz Khan
- Salman Khan
date: '2024-09-01'
publishDate: '2024-10-13T06:34:23.542135Z'
publication_types:
- manuscript
publication: '*arXiv*'
doi: 10.48550/arXiv.2406.09407
abstract: Vision State Space Models (VSSMs), a novel architecture that combines the
  strengths of recurrent neural networks and latent variable models, have demonstrated
  remarkable performance in visual perception tasks by efficiently capturing long-range
  dependencies and modeling complex visual dynamics. However, their robustness under
  natural and adversarial perturbations remains a critical concern. In this work,
  we present a comprehensive evaluation of VSSMs' robustness under various perturbation
  scenarios, including occlusions, image structure, common corruptions, and adversarial
  attacks, and compare their performance to well-established architectures such as
  transformers and Convolutional Neural Networks. Furthermore, we investigate the
  resilience of VSSMs to object-background compositional changes on sophisticated
  benchmarks designed to test model performance in complex visual scenes. We also
  assess their robustness on object detection and segmentation tasks using corrupted
  datasets that mimic real-world scenarios. To gain a deeper understanding of VSSMs'
  adversarial robustness, we conduct a frequency-based analysis of adversarial attacks,
  evaluating their performance against low-frequency and high-frequency perturbations.
  Our findings highlight the strengths and limitations of VSSMs in handling complex
  visual corruptions, offering valuable insights for future research. Our code and
  models will be available at https://github.com/HashmatShadab/MambaRobustness.
tags:
- Computer Science - Computer Vision and Pattern Recognition
links:
- name: URL
  url: http://arxiv.org/abs/2406.09407
---
